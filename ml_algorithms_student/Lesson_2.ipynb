{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JkQFTgKJiqsy"
   },
   "source": [
    "# Урок 2. Масштабирование признаков. Регуляризация. Стохастический градиентный спуск."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JLVfsJXviqs1"
   },
   "source": [
    "## Масштабирование признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Eu5ocQDMiqs2"
   },
   "source": [
    "В машинном обучении при работе с линейными моделями полезной является практика _масштабирования признаков_. Многие методы машинного обучения, в том числе и линейные, наиболее эффективны в том случае, когда признаки имеют одинаковый масштаб. По сути масштабирование означает приведение признаков к какой-то единой шкале. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gsw78QW7iqs3"
   },
   "source": [
    "Существует большое количество методов масштабирования, наиболее популярными из которых являются _нормализация_ и _стандартизация_.\n",
    "\n",
    "Метод __нормализации__ заколючается в приведении признаков к масштабу в диапазоне [0-1].\n",
    "\n",
    "Для его реализации необходимо найти минимальное $min_{j} (x^{j}_{i})$ и максимальное $max_{j} (x^{j}_{i})$ значение признака на обучающей выборке. При этом отмасштабированное значение признака будет находиться по формуле\n",
    "\n",
    "$$x^{j}_{i} = \\frac{x^{j}_{i} - min_{j} (x^{j}_{i})}{max_{j} (x^{j}_{i})-min_{j} (x^{j}_{i})}.$$\n",
    "\n",
    "После преобразования значений признаков минимальное значение превратится в 0, а максимальное - в 1.\n",
    "\n",
    "Пример различия в сходимости алгоритма на сырых и нормализованных данных:\n",
    "<img src=\"images/L2_normalization.png\" style=\"width: 500px;\">\n",
    "\n",
    "__Стандартизация__ заключается в получении своего рода значения сдвига каждого признака от среднего. Для ее реализации необходимо вычислить среднее значение признака \n",
    "\n",
    "$$\\mu_{j} = \\frac{1}{l}\\sum^{l}_{i=1}x^{j}_{i}$$\n",
    "\n",
    "и стандартное отклонение, которое находится путем суммирования квадратов отклонения значений признака на объектах выборки от среднего $\\mu_{j}$ и делением на число объектов выборки с последующим извлечением корня:\n",
    "\n",
    "$$\\sigma_{j} = \\sqrt{\\frac{1}{l}\\sum^{l}_{i=1}(x^{j}_{i}-\\mu_{j})^{2}}$$\n",
    "\n",
    "Чтобы отмасштабировать признак, каждое его значение преобразуется по формуле\n",
    "\n",
    "$$x^{j}_{i}=\\frac{x^{j}_{i} - \\mu_{j}}{\\sigma_{j}}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s32Rv-eFiqs4"
   },
   "source": [
    "Масштабирование является важным этапом подготовки данных перед применением методов машинного обучения. \n",
    "\n",
    "Важным и последним свойством масштабирования является факт, что после масштабирования признаков в линейных моделях веса при них могут интерпретироваться как мера значимости этих признаков.\n",
    "\n",
    "Существуют различные ситуации, когда целесообразно применять тот или иной метод масштабирования. Нормализовать полезно признаки, опирающиеся на величину значений - такие как расстояние. Стандартизировать полезно признаки для модели, которая опирается на распределение. В общем случае, когда выбор метода неочевиден, полезной практикой считается создавать масштабированные копии набора данных, с которыми работает специалист, и сравнивать друг с другом полученные после применения модели результаты для выявления оптимального метода масштабирования для имеющейся ситуации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SMcddg8niqs5"
   },
   "source": [
    "## Стохастический градиентный спуск (SGD, Stochastic Gradient Descent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HkzFJVniiqs6"
   },
   "source": [
    "Вспомним метод градиентного спуска, рассмотренный ранее.\n",
    "\n",
    "На каждой итерации приближение получается вычитанием из предыдущего вектора градиента, умноженного на некоторый шаг:\n",
    "\n",
    "\n",
    "$$w^{k} = w^{k-1} - \\eta_{k}\\nabla Q(w^{k-1}, X).$$\n",
    "\n",
    "При этом выражение градиента в матричной форме выглядит так:\n",
    "\n",
    "$$\\nabla_{w}Q(w,X) = \\frac{2}{l}X^{T}(Xw-y).$$\n",
    "\n",
    "Если расписать $j$-ю компонетну этого градиента, то получим\n",
    "\n",
    "$$\\frac{\\partial Q}{\\partial w_{j}} = \\frac{2}{l}\\sum^{l}_{i=1}x^{j}_{i}(\\left \\langle w,x_{i} \\right \\rangle - y_{i}),$$\n",
    "\n",
    "то есть суммирование по всем $l$ объектам обучающей выборки. Здесь выражение под суммой показывает, как нужно изменить $j$-й вес, чтобы как можно сильнее улучшить качество __на объекте $x_{i}$__, а вся сумма показывает, как нужно изменить вес, чтобы улучшить качество на __всей выборке__.\n",
    "\n",
    "В этой формуле отражен один из главных недостатков градиентного спуска: если выборка большая по объему, то даже один шаг градиентного спуска будет занимать много вычислительных ресурсов и времени."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xlcthp9Uiqs7"
   },
   "source": [
    "Стремление к оптимизации процесса привело к появлению _стохастического градиентного спуска_ (Stochastic gradient descent, SGD). Идея его основана на том, что на одной итерации мы вычитаем не вектор градиента, вычисленный по всей выборке, а вместо этого случайно выбираем один объект из обучающей выборки $x_{i}$ и вычисляем градиент только на этом объекте, то есть градиент только одного слагаемого в функционале ошибки и вычитаем именно этот градиент из текущего приближения вектора весов:\n",
    "\n",
    "$$w^{k} = w^{k-1} - \\eta_{k}\\nabla Q(w^{k-1}, \\{x_{i}\\}),$$\n",
    "\n",
    "то есть $\\nabla Q(w^{k-1}, X)$ заменяется на $\\nabla Q(w^{k-1}, \\{x_{i}\\})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2mKZbftTiqs9"
   },
   "source": [
    "Если в случае градиентного спуска мы стараемся на каждой итерации уменьшить ошибку на всей выборке, и по мере увеличения числа итераций ошибка падает монотонно, то в случае стохастического градиентного спуска мы уменьшаем на каждой итерации ошибку только на одном объекте, но при этом есть вероятность увеличить ее на другом объекте, поэтому график изменения ошибки может получаться немонотонным, и даже иметь пики (см. пример по ссылке [1] из списка литературы). То есть на какой-то итерации мы можем даже увеличить ошибку, но при этом в целом по ходу метода ошибка снижается, и рано или поздно мы выходим на нормальный уровень."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-BBJDLSQiqs-"
   },
   "source": [
    "Реализуем стохастический градиентный спуск своими руками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c7NGnJrtiqs_"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L92vtZuDiqtD"
   },
   "outputs": [],
   "source": [
    "# сгенерируем набор данных\n",
    "data, target, coef = datasets.make_regression(n_samples=1000, n_features = 2, n_informative = 2, n_targets = 1, \n",
    "                                              noise = 5, coef = True, random_state = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4mq1B_FniqtF"
   },
   "source": [
    "Отмасштабируем получившиеся признаки методом стандартизации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rOKEKtFKiqtG"
   },
   "outputs": [],
   "source": [
    "# Получим средние значения и стандартное отклонение по столбцам\n",
    "\n",
    "means = np.mean(data, axis=0)\n",
    "stds = np.std(data, axis=0)\n",
    "# параметр axis указывается для вычисления значений по столбцам, а не по всему массиву\n",
    "#(см. документацию в разделе источников)\n",
    "\n",
    "# вычтем каждое значение признака из среднего и поделим на стандартное отклонение\n",
    "for i in range(data.shape[0]):\n",
    "    for j in range(data.shape[1]):\n",
    "        data[i][j] = (data[i][j] - means[j])/stds[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8BMCZ7uNiqtJ"
   },
   "outputs": [],
   "source": [
    "# реализуем функцию, определяющую среднеквадратичную ошибку\n",
    "def mserror(X, w, y_pred):\n",
    "    y = X.dot(w)\n",
    "    return (sum((y - y_pred)**2)) / len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oFPTJccEiqtO"
   },
   "source": [
    "Подготовка данных и средств проверки закончена. Далее реализуем сам стохастический градиентный спуск."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hwIeP5Y4iqtQ",
    "outputId": "d4ef12c1-fb3e-49c3-ebe3-31b35b53e902"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# инициализируем начальный вектор весов\n",
    "w = np.zeros(2)\n",
    "\n",
    "# список векторов весов после каждой итерации\n",
    "w_list = [w.copy()]\n",
    "\n",
    "# список значений ошибок после каждой итерации\n",
    "errors = []\n",
    "\n",
    "# шаг градиентного спуска\n",
    "eta = 0.01\n",
    "\n",
    "# максимальное число итераций\n",
    "max_iter = 1e5\n",
    "\n",
    "# критерий сходимости (разница весов, при которой алгоритм останавливается)\n",
    "min_weight_dist = 1e-8\n",
    "\n",
    "# зададим начальную разницу весов большим числом\n",
    "weight_dist = np.inf\n",
    "\n",
    "# счетчик итераций\n",
    "iter_num = 0\n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "# ход градиентного спуска\n",
    "while weight_dist > min_weight_dist and iter_num < max_iter:\n",
    "    \n",
    "    # генерируем случайный индекс объекта выборки\n",
    "    train_ind = np.random.randint(data.shape[0])\n",
    "    \n",
    "    new_w = w - 2 * eta * np.dot(data[train_ind].T, \n",
    "                                 (np.dot(data[train_ind], w) - target[train_ind])) / target.shape[0]\n",
    "\n",
    "    weight_dist = np.linalg.norm(new_w - w, ord=2)\n",
    "    \n",
    "    w_list.append(new_w.copy())\n",
    "    errors.append(mserror(data, new_w, target))\n",
    "    \n",
    "    iter_num += 1\n",
    "    w = new_w\n",
    "    \n",
    "w_list = np.array(w_list)\n",
    "\n",
    "print(f'В случае использования стохастического градиентного спуска функционал ошибки составляет \\\n",
    "      {round(errors[-1], 4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B-cN_umsiqtU"
   },
   "source": [
    "Для стохастического градиентного спуска мы увеличили максимальное число итераций (max_iter) до 10000, что естественно, так как из-за специфики метода для достижения сходимости нужно большее количество шагов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mq8gHc1iiqtU",
    "outputId": "25bd89c1-1ea5-47cd-8131-13371cad8077"
   },
   "outputs": [],
   "source": [
    "# Визуализируем изменение весов (красной точкой обозначены истинные веса, сгенерированные вначале)\n",
    "plt.figure(figsize=(13, 6))\n",
    "plt.title('Stochastic gradient descent')\n",
    "plt.xlabel(r'$w_1$')\n",
    "plt.ylabel(r'$w_2$')\n",
    "\n",
    "plt.scatter(w_list[:, 0], w_list[:, 1])\n",
    "plt.scatter(coef[0], coef[1], c='r')\n",
    "plt.plot(w_list[:, 0], w_list[:, 1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MXCKz_wliqtZ",
    "outputId": "b57d60a0-b120-45b2-a4bc-5f70fbbdfa4f"
   },
   "outputs": [],
   "source": [
    "# Визуализируем изменение функционала ошибки\n",
    "plt.plot(range(len(errors[-100:])), errors[-100:])\n",
    "plt.title('MSE')\n",
    "plt.xlabel('Iteration number')\n",
    "plt.ylabel('MSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QchXLomyiqte"
   },
   "source": [
    "Как и в случае градиентного спуска, вектор весов приближается к истинному. При этом падает и ошибка. Сравнить скорость ее падения для двух методов вам предстоит в домашнем задании.\n",
    "\n",
    "Добиться лучшей скорости сходимости в методе стохастического градиентного спуска можно варьируя величину шага или используя методы, подбирающие ее адаптивно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a_19JViDiqtg"
   },
   "source": [
    "Среди преимуществ SGD можно выделить гораздо более быстрое вычисление одного шага по сравнению с обычным градиентным спуском и отсутствие необходимости хранить всю выборку в памяти при работе метода, что в свою очередь позволяет работать с очень большими выборками, которые невозможно поместить в память."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pZXExx-Yiqth"
   },
   "source": [
    "## Переобучение (overfitting) и методы борьбы с ним"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JB93X534iqth"
   },
   "source": [
    "Чтобы понять смысл переобучения и недообучения, начнем с примера. Допустим, у нас есть исходная известная зависимость 3-го порядка:\n",
    "\n",
    "$$f(x) = 0.6 - 13.2x - 5.3 x^{2} - 4.17x^{3}.$$\n",
    "\n",
    "Реализуем ее в виде python-функции и построим график."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-x7O02fBiqti"
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return 0.6 - 13.2 * x - 5.3 * x ** 2 - 4.17 * x ** 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iZU05q4miqtk",
    "outputId": "2ff55331-ed9c-4a9c-d13e-15634e8f5643"
   },
   "outputs": [],
   "source": [
    "dots = np.linspace(-10, 10, 100)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.ylim(-5000, 5000)\n",
    "plt.xlim(-10,10)\n",
    "\n",
    "plt.plot(dots, f(dots), color='g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RY1HQExXiqtn"
   },
   "source": [
    "Теперь сгенерируем датасет из десяти случайных точек, подчиняющихся этой зависимости, с добавлением шума и нанесем на график."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D8aLmQt2iqto"
   },
   "outputs": [],
   "source": [
    "np.random.seed(16)\n",
    "x_data = np.random.uniform(-10, 10, 10)\n",
    "f_data = [f(i) for i in x_data] + np.random.uniform(-1000, 1000, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OtY-zFVaiqtq",
    "outputId": "b7a8cc00-baea-44a8-9242-dab8943ecc41"
   },
   "outputs": [],
   "source": [
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.ylim(-5000, 5000)\n",
    "plt.xlim(-10,10)\n",
    "\n",
    "plt.plot(dots, f(dots), color='g')\n",
    "plt.scatter(x_data, f_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zMHWU0yAiqt0"
   },
   "source": [
    "Теперь попробуем создать модель, способную восстановить исходную зависимость. Самым примитивным так называемый __константный алгоритм__, то есть модель вида \n",
    "\n",
    "$$a(x) = w_{0}.$$\n",
    "\n",
    "Зависимость такой модели от признаков будет иметь вид горизонтальной прямой, что, очевидно, не обобщает нашу зависимость в должном виде (см. график ниже)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8mYrEwYtiqt0",
    "outputId": "64e1758a-e946-4cc2-d346-d10da99d55ae"
   },
   "outputs": [],
   "source": [
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.ylim(-5000, 5000)\n",
    "plt.xlim(-10,10)\n",
    "\n",
    "plt.plot(dots, f(dots), color='g')\n",
    "plt.scatter(x_data, f_data)\n",
    "plt.plot(dots, [dots.mean()]*len(dots), color='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JGkSELuTiqt3"
   },
   "source": [
    "Далее усложним семейство алгоритмов, применив линейную регрессию, которая в случае одного признака будет иметь вид \n",
    "\n",
    "$$a(x) = w_{0} + w_{1}x.$$\n",
    "\n",
    "Обучим соответствующую модель, применив для этого методы python \"из коробки\" для работы с линейной регрессией."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XIhKhnC0iqt4",
    "outputId": "647aa2f0-ffd2-4598-c332-ffdb1c76cb8f"
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "# создадим модель\n",
    "linear_regressor = linear_model.LinearRegression()\n",
    "\n",
    "# обучим ее\n",
    "linear_regressor.fit(np.reshape(x_data, (-1, 1)), f_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zFLiACBZiqt7",
    "outputId": "03d85c51-0059-4ee3-902a-a037402d2ac5"
   },
   "outputs": [],
   "source": [
    "# выведем полученный вес при признаке и свободный коэффициент\n",
    "print(linear_regressor.coef_[0], linear_regressor.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1TEVNRsgiquB"
   },
   "source": [
    "Нанесем полученную после обучения модель на график"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TmbR6vRniquD",
    "outputId": "db673d33-8110-402a-e2db-ef73e092b77f"
   },
   "outputs": [],
   "source": [
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.ylim(-5000, 5000)\n",
    "plt.xlim(-10,10)\n",
    "\n",
    "plt.plot(dots, f(dots), color='g')\n",
    "plt.scatter(x_data, f_data)\n",
    "plt.plot(dots, linear_regressor.predict(np.reshape(dots, (-1, 1))), color='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OVSKKmTmiquJ"
   },
   "source": [
    "Мы обучили линейную модель, и видимо, что она, как и константная, плохо восстанавливает исходную зависимость. В данном случае можно говорить о __недообучении__. Хороший алгоритм не был построен, поскольку с помощью выбранного семейства алгоритмов невозможно восстановить исходную закономерность."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "km9OjqjGiquK"
   },
   "source": [
    "Усложним используемое семейство алгоритмов до кубической зависимости \n",
    "\n",
    "$$a(x) = w_{0} + w_{1}x + w_{2}x^{2} + w_{3}x^{3}.$$\n",
    "\n",
    "Сделаем это путем искусственной генерации новой матрицы признаков, состоящей из исходных $x$, возведенных в степени до 3, используя `sklearn.preprocessing.PolynomialFeatures`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iDLG2XuViquL",
    "outputId": "2bd60151-46f9-4b64-f1f4-d21da948095a"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# создадим новую кубическую модель\n",
    "third_degree_regressor = make_pipeline(PolynomialFeatures(degree=3), linear_model.LinearRegression())\n",
    "\n",
    "# обучим ее\n",
    "third_degree_regressor.fit(np.reshape(x_data, (-1, 1)), f_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9kY0H8KPiquS",
    "outputId": "b6cdedec-6da3-4bb3-e8c8-077a3d0713ff"
   },
   "outputs": [],
   "source": [
    "# выведем полученные веса при признаках и свободный коэффициент\n",
    "print(third_degree_regressor.named_steps.linearregression.coef_)\n",
    "print(third_degree_regressor.named_steps.linearregression.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OBKM6B6wiquV"
   },
   "source": [
    "Нанесем полученную в итоге зависимость на график."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6rKHJTjJiquW",
    "outputId": "7c012ee6-6aa2-426d-ce4d-15316b59f3c7"
   },
   "outputs": [],
   "source": [
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.ylim(-5000, 5000)\n",
    "plt.xlim(-10,10)\n",
    "\n",
    "plt.plot(dots, f(dots), color='g')\n",
    "plt.scatter(x_data, f_data)\n",
    "plt.plot(dots, third_degree_regressor.predict(np.reshape(dots, (-1, 1))), color='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9VJdL3rhiquY"
   },
   "source": [
    "Полученный алгоритм достаточно хорошо описывает данные, но не идеально. И в реальных условиях может возникнуть вопрос, можно ли добиться лучшего совпадения увеличением сложности алгоритма.\n",
    "\n",
    "Проиллюстрируем, что происходит в случае использования многочлена 8-й степени."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vc8pOjbOiquZ",
    "outputId": "f456a08c-224d-4bb9-d633-bcc6e0647dfb"
   },
   "outputs": [],
   "source": [
    "# создадим модель 8-й степени\n",
    "eighth_degree_regressor = make_pipeline(PolynomialFeatures(degree=8), linear_model.LinearRegression())\n",
    "\n",
    "# обучим ее\n",
    "eighth_degree_regressor.fit(np.reshape(x_data, (-1, 1)), f_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y8dlT6n5iquc"
   },
   "source": [
    "Покажем получившийся график зависимости."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VW7kvdoFiqud",
    "outputId": "96550f3e-f944-400b-fe2e-3e2890353751",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.ylim(-5000, 5000)\n",
    "plt.xlim(-10,10)\n",
    "\n",
    "plt.plot(dots, f(dots), color='g')\n",
    "plt.scatter(x_data, f_data)\n",
    "plt.plot(dots, eighth_degree_regressor.predict(np.reshape(dots, (-1, 1))), color='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JkFoaeMCiquk"
   },
   "source": [
    "Видно, что новая модель лучше описывает имеющиеся в обучающей выборке данные и дает фактически идеальные ответы на них, но про этом в целом зависимость сильно отличается от истинной. Поэтому если мы попробуем применить эту модель на новых данных, ответы будут расходиться с правильными. Такое явление и называется __переобучением__. Алгоритм слишком сильно подогнан под обучающую выборку, и за счет этого будет давать неадекватные ответы на новых точках."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CErR0qKOiquk"
   },
   "source": [
    "Таким образом, недообучение несет за собой плохое качество на обучении и на новых данных, а переобучение - хорошее качество на обучении и плохое на новых данных.\n",
    "\n",
    "Понятно, как бороться с недообучением - усложнять семейство алгоритмов. Возникает вопрос, как выявить переобучение и его избежать. В случае переобучения, как было сказано ранее, данные из обучающей выборки алгоритмом будут описываться хорошо, а новые данные - плохо, поэтому используя только обучающую выборку, невозможно заключить, хорошо обучен алгоритм или переобучен, так как оба они будут хорошо описывать известные данные."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g9MMDQHDiqul"
   },
   "source": [
    "Есть несколько методов оценки качества алгоритма и выявления переобучения:\n",
    "\n",
    "1. Не использовать всю выборку для обучения, а откладывать часть данных для проверки полученного алгоритма. Это называется _отложенной выборкой_. Данные делятся на обучающую и тестовую выборку в соотношении, например, 0.7 к 0.3, и затем на первой части алгоритм обучается, а на второй проверяется. Размер отложенной выборки в данном случае нужно подбирать с осторожностью, так как слишком маленькая тестовая выборка не будет обеспечивать должной точности оценки качества обучения, а слишком маленькия обучающая выборка приведет к снижению качества обучения, так как будет малорепрезентативна. Таким образом, главный минус этого метода - сильная зависимость результата от того, как мы выбираем отложенную выборку. Например, в пространстве объектов могут быть какие-то особые, отличающиеся от остальных по какому-то свойству объекты, и может так произойти, что после разбиения они не попадут в обучающую выборку, алгоритм на них не обучится, и качество обучения после проверки на этих объектах, попавших в тестовую выборку, будет плохим. Один из путей решения этой проблемы - многократное случайное разбиение выборки на тестовую и обучающую и использование в качестве оценки качества среднего значения ошибки полученной после каждого разбиения. Но и этот метод не гарантирует, что каждый объект побывает в обучающей выборке, так как разбиения случайные.\n",
    "\n",
    "\n",
    "2. _Кросс-валидация_ (усложненная версия метода отложенной выборки). Этот метод как раз вытекает из проблемы, описанной выше. Он является более системным подходом. В этом случае выборка разбивается на $k$ блоков, и затем каждый из них по очереди используется в качестве тестового, а остальная часть - в качестве обучающей выборки. После прохождения всей выборки таким образом получается $k$ показателей качества, и итоговая оценка качества обучения по кросс-валидации оценивается как средняя из этих $k$. В этом случае мы гарантируем, что все данные поучаствуют в обучении. Выбор количества блоков $k$ обычно зависит от размера выборки. Чем больше данных, тем меньше нужно блоков, так как во-первых в этом случае после разбиения даже на малое количество блоков у нас остается большой объем данных в обучающей выборке, что обеспечивает хорошее качество обучения, а во-вторых, разбиение на $k$ блоков означает обучение алгоритма $k$ раз, соответственно, чем их больше, тем больше получается вычислительная сложность процесса обучения модели. Обычно $k$ принимает значение от 3 до 10.\n",
    "\n",
    "\n",
    "3. Использовать меры сложности модели, позволяющие без дополнительной выборки выявить переобучение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_I6dPoI0iqum"
   },
   "source": [
    "Одним из знаков, что произошло переобучение модели, или _мерой сложности_ является получение больших по модулю весов при признаках. Посмотрим, что получилось в нашей последней модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H4vCY2DJiqum",
    "outputId": "24e975e6-1b94-4518-d817-569837122aa3"
   },
   "outputs": [],
   "source": [
    "# выведем полученные веса при признаках и свободный коэффициент\n",
    "print(eighth_degree_regressor.named_steps.linearregression.coef_)\n",
    "print(eighth_degree_regressor.named_steps.linearregression.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3CveLhp1iqup"
   },
   "source": [
    "Видим веса 2 и 3 порядков в то время как в кубичесой модели и в исходной зависимости ничего подобного не было. Это и говорит нам о том, что в данном случае имеет место переобучение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H_sCR6rXiqup"
   },
   "source": [
    "На этой особенности и основывается метод _регуляризации_ для борьбы с переобучением."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ws1-N-_Qiqus"
   },
   "source": [
    "### Регуляризация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8Zgvr4aEiqut"
   },
   "source": [
    "Метод регуляризации заключается в \"штрафовании\" модели за слишком большие веса путем добавления нового члена к среднеквадратичной ошибке:\n",
    "\n",
    "$$Q(w, X) + \\lambda ||w||^{2} \\rightarrow \\underset{w}{\\text{min}}.$$\n",
    "\n",
    "добавленный член $\\lambda ||w||^{2}$ - _квадратичный регуляризатор_, который представляет собой $L_{2}$-норму вектора весов, то есть сумму квадратов весов $\\sum^{d}_{j=1}w_{j}^{2}$, коэффицент $\\lambda$ при нем - коэффициент регуляризации. Чем больше его значение, тем меньшая сложность модели будет получаться в процессе такого обучения. Если увеличивать его, в какой-то момент оптимальным для модели окажется зануление всех весов. В то же время при слишком низких его значениях появляется вероятность чрезмерного усложнения модели и переобучения. Выбор оптимального значения этого коэфициента является отдельной задачей и заключается в многократном обучении модели с разными его значениями и сравнении их качества."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yP69lwhriqut"
   },
   "source": [
    "По сути, смысл регуляризации заключается, как и в обычном обучении, в минимизации функционала ошибки, только в данном случае добавляется условие непревышения нормой вектора весов некоторого значения $||w||^{2}\\leq C$, то есть ограничение весов, что и будет залогом избежания переобучения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-OTMLxupiquu"
   },
   "source": [
    "Описанный выше метод с использованием $L_{2}$-нормы вектора весов в качестве регуляризатора называется _$L_{2}$-регуляризацией_. По аналогии существует также _$L_{1}$-регуляризация_, использующая в качестве регуляризатора $L_{1}$-норму вектора весов, то есть сумму модулей весов.\n",
    "\n",
    "$$||w||_{1} = \\sum^{d}_{j=1}|w_{j}|.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EJFR2HDliqu1"
   },
   "source": [
    "$L_{2}$-регуляризатор представляет собой непрерывную гладкую функцию, поэтому его добавление не усложняет использование градиентных методов оптимизации, так как в каждой его точке существует производная. $L_{1}$-регуляризатор уже не является гладкой функцией, так как в нем есть модуль, у которого не существует производной в нуле. То есть его использование усложняет градиентные методы оптимизации, но в свою очередь он обладает интересной особенностью, заключающейся в занулении некоторых весов при его применении. Иными словами, он производит отбор признаков, позволяя оставлять только самые важные, отбрасывая остальные."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IjeEm_Geiqu2"
   },
   "source": [
    "$L_{1}$-регуляризация также называется Lasso, $L_{2}$-регуляризация иногда называется Ridge. По этим именам регуляризаторы можно найти в модуле `sklearn.linear_models`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lq5zA2Itiqu3"
   },
   "source": [
    "### Коэффициент детерминации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1e7sgEO5iqu3"
   },
   "source": [
    "_Коэффициент детерминации_ $R^{2}$ является еще одной метрикой качества в задачах регрессии. Ранее мы говорили о средней абсолютной и среднеквадратичной ошибке. Коэффициент детерминации позволяет развить тему среднеквадратичной ошибки, интерпретируя ее. \n",
    "\n",
    "MSE не позволяет сама по себе сделать вывод о том, как хорошо модель решает задачу. Например, если целевая переманная принимает значения от 0 до 1, а MSE равняется 10, это плохой показатель, а когда целевая переменная варьируется от 1000 до 10000, такое же значение уже является очень хорошим. Для избавления от такой неясности и был введен коэффициент детерминации, который по сути является нормированной среднеквадратичной ошибкой и принимает значения от 0 до 1.\n",
    "\n",
    "$$R^{2} = 1 - \\frac{\\sum^{l}_{i=1}(a(x_{i}) - y_{i})^{2}}{\\sum^{l}_{i=1}(y_{i} - \\bar{y})^{2}},$$\n",
    "\n",
    "где $\\bar{y}=\\frac{1}{l}\\sum^{l}_{i=1}y_{i}$ - среднее значение целевой переменной.\n",
    "\n",
    "Коэффициент детерминации характеризует, какую долю дисперсии ответов объясняет модель. Если $R^{2}=1$, то модель идеально описывает данные, если же $R^{2}$ близко к нулю, то предсказания сопоставимы по качеству с константной моделью."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "esNMM7hXiqu4"
   },
   "source": [
    "## Литература"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vPQPnl--iqu4"
   },
   "source": [
    "1. [Стохастический градиентный спуск](http://www.machinelearning.ru/wiki/index.php?title=%D0%A1%D1%82%D0%BE%D1%85%D0%B0%D1%81%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B8%D0%B9_%D0%B3%D1%80%D0%B0%D0%B4%D0%B8%D0%B5%D0%BD%D1%82%D0%BD%D1%8B%D0%B9_%D1%81%D0%BF%D1%83%D1%81%D0%BA)\n",
    "2. [Методы градиентного спуска](http://www.machinelearning.ru/wiki/index.php?title=%D0%9C%D0%B5%D1%82%D0%BE%D0%B4_%D0%B3%D1%80%D0%B0%D0%B4%D0%B8%D0%B5%D0%BD%D1%82%D0%BD%D0%BE%D0%B3%D0%BE_%D1%81%D0%BF%D1%83%D1%81%D0%BA%D0%B0)\n",
    "3. [sklearn.datasets.make_regression](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_regression.html)\n",
    "4. [numpy.mean](https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.mean.html)\n",
    "5. [sklearn.linear_model.LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)\n",
    "6. [sklearn.preprocessing.PolynomialFeatures](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html)\n",
    "7. [Обзор методов отбора признаков](https://habr.com/ru/company/jetinfosystems/blog/470622/)\n",
    "8. [sklearn.linear_model.ElasticNet](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Масштабирование признаков - хорошая практика, позволяющая обучать модели быстрее и делающая их более точными\n",
    "* При использовании метрических алгоритмов масштабирование обязательно (!)\n",
    "* Стохастический градиентный спуск (SGD) - на каждом шаге уменьшаем ошибку только на одном объекте (или нескольких), а не на всей выборке, работает быстрее обычного GD, т.к. меньше вычислений\n",
    "* SGD из-за стохастичности может \"перепрыгнуть\" локальный минимум и попасть в глобальный\n",
    "* Переобучение - модель \"выучила\" выборку, но обобщающая способность слабая\n",
    "* Признаки переобучения: качество на трейне высокое, а на тесте низкое, большие веса модели\n",
    "* Один из способов борьбы с переобучением - регуляризация - штраф за большие веса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q&A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1. Какие еще разновидности градиентного спуска бывают, помимо классического и стохастического?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- классический с постоянным шагом\n",
    "<img src=\"images/L2_Grad1.png\" style=\"width: 500px;\">\n",
    "Геометрическая интерпретация метода градиентного спуска с постоянным шагом: на каждом шаге мы сдвигаемся по вектору антиградиента, \"уменьшенному в $\\lambda$ раз\".\n",
    "\n",
    "\n",
    "- стохастический\n",
    "\n",
    "В отличие от обычного градиентного спуска, градиент оптимизируемой функции считается на каждом шаге не как сумма градиентов от каждого элемента выборки, а как градиент от одного, случайно выбранного элемента, или же градиента от батча\n",
    "\n",
    "- с дроблением шага\n",
    "<img src=\"images/L2_Grad2.png\" style=\"width: 800px;\">\n",
    "\n",
    "\n",
    "- наискорейший\n",
    "<img src=\"images/L2_Grad4_1.png\" style=\"width: 780px;\">\n",
    "<img src=\"images/L2_Grad4_2.png\" style=\"width: 500px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2. Почему при L1 регуляризации веса зануляются?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для понимания складываем три кусочка пазла:\n",
    "1. [Метод множителей Лагранжа](https://ru.wikipedia.org/wiki/%D0%9C%D0%B5%D1%82%D0%BE%D0%B4_%D0%BC%D0%BD%D0%BE%D0%B6%D0%B8%D1%82%D0%B5%D0%BB%D0%B5%D0%B9_%D0%9B%D0%B0%D0%B3%D1%80%D0%B0%D0%BD%D0%B6%D0%B0)\n",
    "2. [Условия Каруша — Куна — Таккера](https://ru.wikipedia.org/wiki/%D0%A3%D1%81%D0%BB%D0%BE%D0%B2%D0%B8%D1%8F_%D0%9A%D0%B0%D1%80%D1%83%D1%88%D0%B0_%E2%80%94_%D0%9A%D1%83%D0%BD%D0%B0_%E2%80%94_%D0%A2%D0%B0%D0%BA%D0%BA%D0%B5%D1%80%D0%B0)\n",
    "3. [Связный текст по теме](http://www.machinelearning.ru/wiki/images/7/7e/VetrovSem11_LARS.pdf)\n",
    " \n",
    "<img src=\"images/L2_L1.png\" style=\"width: 500px;\">\n",
    "Резюме идеи: \n",
    "\n",
    "- подбирая $\\lambda$, мы косвено решаем задачу Лагранжа \n",
    "- при L1 веса зануляются, так как оптимум приходится на точку на оси"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3. Можно ли применить одновременно L1 и L2 регуляризацию?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Да, L1+L2 регуляризация называется Elastic Net. Про это можно почитать [здесь](http://enhancedatascience.com/2017/07/04/machine-learning-explained-regularization/) и в оригинальной [статье](https://web.stanford.edu/~hastie/Papers/B67.2%20(2005)%20301-320%20Zou%20&%20Hastie.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__4. Аналитическое решение задачи линейной регрессии красивое и лаконичное, но сложность обращения матрицы $О(n^3)$, что плохо. Может быть можно как-то оптимизировать аналитическое решение?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Да, можно. Получению формулы для весов $$w = (X^{T}X)^{-1}X^{T}y$$ предшествует шаг: $$X^{T}Xw = X^{T}y$$ Перепишем уравнение в виде $$Aw = b$$ где $$A = X^{T}X, b = X^{T}y$$ Применим к матрице $A$ разложение Холецкого ([описание 1](https://algowiki-project.org/ru/%D0%A0%D0%B0%D0%B7%D0%BB%D0%BE%D0%B6%D0%B5%D0%BD%D0%B8%D0%B5_%D0%A5%D0%BE%D0%BB%D0%B5%D1%86%D0%BA%D0%BE%D0%B3%D0%BE_(%D0%BC%D0%B5%D1%82%D0%BE%D0%B4_%D0%BA%D0%B2%D0%B0%D0%B4%D1%80%D0%B0%D1%82%D0%BD%D0%BE%D0%B3%D0%BE_%D0%BA%D0%BE%D1%80%D0%BD%D1%8F)), [описание 2](https://ru.wikipedia.org/wiki/%D0%A0%D0%B0%D0%B7%D0%BB%D0%BE%D0%B6%D0%B5%D0%BD%D0%B8%D0%B5_%D0%A5%D0%BE%D0%BB%D0%B5%D1%86%D0%BA%D0%BE%D0%B3%D0%BE)), при котором матрица $A$ представляется в виде произведения двух матриц: $A = LL^*$ (в случае вещественных чисел $A = LL^T$). Тогда исходное уравнение можно записать как $$LL^*w = b$$ и решить сначала прямой подстановкой $$Lv = b$$ поскольку $L$ — нижняя треугольная матрица, а затем решить обратной подстановкой $$L^*w = v$$ поскольку $L^*$ — верхняя треугольная матрица.\n",
    "\n",
    "Для разложения Холецкого есть метод в numpy - [numpy.linalg.cholesky](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.cholesky.html). Альтернативой методу Холецкого может служить [LU-разложение](https://ru.wikipedia.org/wiki/LU-%D1%80%D0%B0%D0%B7%D0%BB%D0%BE%D0%B6%D0%B5%D0%BD%D0%B8%D0%B5), которое чуть быстрее, но требует хранения в памяти всей матрицы, хотя разложение Холецкого - только половины."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Ws1-N-_Qiqus",
    "Lq5zA2Itiqu3"
   ],
   "name": "Lesson_2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
